{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/tancik/fourier-feature-networks/blob/master/Experiments/3d_MRI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"W2CrDTYL3c-C"},"source":["# 3D MRI reconstruction with sparse bvals\n"]},{"cell_type":"code","source":["!pip install --upgrade pip\n","\n","# CUDA 12 installation\n","# Note: wheels only available on linux.\n","# !pip install --upgrade \"jax[cuda12_pip]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n","\n","# CUDA 11 installation\n","# Note: wheels only available on linux.\n","!pip install --upgrade \"jax[cuda11_pip]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tRPgqdL_j5i9","executionInfo":{"status":"ok","timestamp":1710430882008,"user_tz":420,"elapsed":1012601,"user":{"displayName":"Ni Chen","userId":"06056723126215624619"}},"outputId":"d721b184-9864-4c73-a87b-18da17c3991f"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n","Requirement already satisfied: jax[cuda11_pip] in /usr/local/lib/python3.10/dist-packages (0.4.23)\n","Collecting jax[cuda11_pip]\n","  Downloading jax-0.4.25-py3-none-any.whl (1.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax[cuda11_pip]) (0.2.0)\n","Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from jax[cuda11_pip]) (1.25.2)\n","Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax[cuda11_pip]) (3.3.0)\n","Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax[cuda11_pip]) (1.11.4)\n","Collecting jaxlib==0.4.25+cuda11.cudnn86 (from jax[cuda11_pip])\n","  Downloading https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.4.25%2Bcuda11.cudnn86-cp310-cp310-manylinux2014_x86_64.whl (130.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.3/130.3 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu11>=11.11 (from jax[cuda11_pip])\n","  Downloading nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu11>=11.8 (from jax[cuda11_pip])\n","  Downloading nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-nvcc-cu11>=11.8 (from jax[cuda11_pip])\n","  Downloading nvidia_cuda_nvcc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (19.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu11>=11.8 (from jax[cuda11_pip])\n","  Downloading nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu11>=8.8 (from jax[cuda11_pip])\n","  Downloading nvidia_cudnn_cu11-8.9.6.50-py3-none-manylinux1_x86_64.whl (699.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m699.9/699.9 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu11>=10.9 (from jax[cuda11_pip])\n","  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu11>=11.4 (from jax[cuda11_pip])\n","  Downloading nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu11>=11.7 (from jax[cuda11_pip])\n","  Downloading nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu11>=2.18.3 (from jax[cuda11_pip])\n","  Downloading nvidia_nccl_cu11-2.20.5-py3-none-manylinux2014_x86_64.whl (142.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.9/142.9 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11 (from nvidia-cudnn-cu11>=8.8->jax[cuda11_pip])\n","  Downloading nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-nvcc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, jaxlib, jax\n","  Attempting uninstall: jaxlib\n","    Found existing installation: jaxlib 0.4.23+cuda12.cudnn89\n","    Uninstalling jaxlib-0.4.23+cuda12.cudnn89:\n","      Successfully uninstalled jaxlib-0.4.23+cuda12.cudnn89\n","  Attempting uninstall: jax\n","    Found existing installation: jax 0.4.23\n","    Uninstalling jax-0.4.23:\n","      Successfully uninstalled jax-0.4.23\n","Successfully installed jax-0.4.25 jaxlib-0.4.25+cuda11.cudnn86 nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvcc-cu11-11.8.89 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-8.9.6.50 nvidia-cufft-cu11-10.9.0.58 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.20.5\n"]}]},{"cell_type":"code","source":["!pip install jaxlib\n","# !pip install neural-tangents\n","# !pip install tqdm\n","# !pip install Livelossplot\n","# !pip install imageio\n","# !pip install PIL\n","# !pip install cv2\n","# !pip install numpy\n","# !pip install matplotlib\n","# !pip install phantominator\n","# !pip install gdown\n","\n","# !pip install Embree\n","# !pip install pyembree\n","# !pip install trimesh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0FfxC0HukXk8","executionInfo":{"status":"ok","timestamp":1710431242194,"user_tz":420,"elapsed":6213,"user":{"displayName":"Ni Chen","userId":"06056723126215624619"}},"outputId":"a62e1857-83f7-4300-d038-6f1054986cde"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (0.4.25+cuda11.cudnn86)\n","Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jaxlib) (1.11.4)\n","Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from jaxlib) (1.26.4)\n","Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jaxlib) (0.2.0)\n"]}]},{"cell_type":"code","source":["!pip install -q livelossplot\n","!pip install -q phantominator"],"metadata":{"id":"Yff2Nxat1BHJ","executionInfo":{"status":"ok","timestamp":1710431176473,"user_tz":420,"elapsed":16710,"user":{"displayName":"Ni Chen","userId":"06056723126215624619"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"iE4vCQ0buGgM","cellView":"both","executionInfo":{"status":"ok","timestamp":1710431494964,"user_tz":420,"elapsed":3187,"user":{"displayName":"Ni Chen","userId":"06056723126215624619"}}},"source":["import jax\n","from jax import random, grad, jit, vmap, lax\n","# from jax.config import config\n","import jax.numpy as np\n","from jax.scipy import ndimage\n","# from jax.experimental import optimizers, stax\n","from jax.example_libraries import stax, optimizers\n","# from jax.ops import index, index_update\n","import random as py_random\n","\n","from livelossplot import PlotLosses\n","import matplotlib.pyplot as plt\n","from tqdm.notebook import tqdm as tqdm\n","import os\n","import requests\n","from io import BytesIO\n","\n","import cv2\n","import scipy.ndimage\n","from scipy.special import binom\n","\n","from tqdm.notebook import tqdm as tqdm\n","import numpy as onp\n","\n","from phantominator import shepp_logan, ct_shepp_logan, ct_modified_shepp_logan_params_3d\n","\n","## Random seed\n","rand_key = random.PRNGKey(10)\n","\n","prop_cycle = plt.rcParams['axes.prop_cycle']\n","colors = prop_cycle.by_key()['color']\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"j-SocmlMQxdm"},"source":["#@markdown #Global Defaults\n","\n","#@markdown resolution\n","RES = 96 #@param"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d2OmVKOQZCoA","cellView":"form"},"source":["#@title NP Area Resize Code\n","\n","# from https://gist.github.com/shoyer/c0f1ddf409667650a076c058f9a17276\n","\n","def _reflect_breaks(size: int) -> np.ndarray:\n","  \"\"\"Calculate cell boundaries with reflecting boundary conditions.\"\"\"\n","  result = np.concatenate([[0], 0.5 + np.arange(size - 1), [size - 1]])\n","  assert len(result) == size + 1\n","  return result\n","\n","def _interval_overlap(first_breaks: np.ndarray,\n","                      second_breaks: np.ndarray) -> np.ndarray:\n","  \"\"\"Return the overlap distance between all pairs of intervals.\n","\n","  Args:\n","    first_breaks: breaks between entries in the first set of intervals, with\n","      shape (N+1,). Must be a non-decreasing sequence.\n","    second_breaks: breaks between entries in the second set of intervals, with\n","      shape (M+1,). Must be a non-decreasing sequence.\n","\n","  Returns:\n","    Array with shape (N, M) giving the size of the overlapping region between\n","    each pair of intervals.\n","  \"\"\"\n","  first_upper = first_breaks[1:]\n","  second_upper = second_breaks[1:]\n","  upper = np.minimum(first_upper[:, np.newaxis], second_upper[np.newaxis, :])\n","\n","  first_lower = first_breaks[:-1]\n","  second_lower = second_breaks[:-1]\n","  lower = np.maximum(first_lower[:, np.newaxis], second_lower[np.newaxis, :])\n","\n","  return np.maximum(upper - lower, 0)\n","\n","def _resize_weights(\n","    old_size: int, new_size: int, reflect: bool = False) -> np.ndarray:\n","  \"\"\"Create a weight matrix for resizing with the local mean along an axis.\n","\n","  Args:\n","    old_size: old size.\n","    new_size: new size.\n","    reflect: whether or not there are reflecting boundary conditions.\n","\n","  Returns:\n","    NumPy array with shape (new_size, old_size). Rows sum to 1.\n","  \"\"\"\n","  if not reflect:\n","    old_breaks = np.linspace(0, old_size, num=old_size + 1)\n","    new_breaks = np.linspace(0, old_size, num=new_size + 1)\n","  else:\n","    old_breaks = _reflect_breaks(old_size)\n","    new_breaks = (old_size - 1) / (new_size - 1) * _reflect_breaks(new_size)\n","\n","  weights = _interval_overlap(new_breaks, old_breaks)\n","  weights /= np.sum(weights, axis=1, keepdims=True)\n","  assert weights.shape == (new_size, old_size)\n","  return weights\n","\n","def resize(array: np.ndarray,\n","           shape: [int, ...],\n","           reflect_axes: [int] = ()) -> np.ndarray:\n","  \"\"\"Resize an array with the local mean / bilinear scaling.\n","\n","  Works for both upsampling and downsampling in a fashion equivalent to\n","  block_mean and zoom, but allows for resizing by non-integer multiples. Prefer\n","  block_mean and zoom when possible, as this implementation is probably slower.\n","\n","  Args:\n","    array: array to resize.\n","    shape: shape of the resized array.\n","    reflect_axes: iterable of axis numbers with reflecting boundary conditions,\n","      mirrored over the center of the first and last cell.\n","\n","  Returns:\n","    Array resized to shape.\n","\n","  Raises:\n","    ValueError: if any values in reflect_axes fall outside the interval\n","      [-array.ndim, array.ndim).\n","  \"\"\"\n","  reflect_axes_set = set()\n","  for axis in reflect_axes:\n","    if not -array.ndim <= axis < array.ndim:\n","      raise ValueError('invalid axis: {}'.format(axis))\n","    reflect_axes_set.add(axis % array.ndim)\n","\n","  output = array\n","  for axis, (old_size, new_size) in enumerate(zip(array.shape, shape)):\n","    reflect = axis in reflect_axes_set\n","    weights = _resize_weights(old_size, new_size, reflect=reflect)\n","    product = np.tensordot(output, weights, [[axis], [-1]])\n","    output = np.moveaxis(product, -1, axis)\n","  return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JE2lAycwZJJn","executionInfo":{"status":"ok","timestamp":1710431500707,"user_tz":420,"elapsed":147,"user":{"displayName":"Ni Chen","userId":"06056723126215624619"}}},"source":["#@title Shepp Data Gen\n","\n","def get_shepp_dataset_3D(rand_key, num_grid_search_samples, test_samples):\n","    total_samples = num_grid_search_samples + test_samples\n","\n","    ct_params = np.array(ct_modified_shepp_logan_params_3d())\n","\n","    shepps = []\n","    for i in range(total_samples):\n","        rand_key, subkey = random.split(rand_key)\n","        i_ct_params = ct_params + random.normal(subkey, shape=ct_params.shape)/20.0\n","        shepps.append(np.clip(ct_shepp_logan((RES,RES,RES), E=i_ct_params, zlims=(-0.25,0.25)), 0.0, 1.0))\n","\n","    samples = np.stack(shepps, axis=0)\n","\n","    out = {\n","        \"data_grid_search\":np.array(samples[:num_grid_search_samples,:,:]),\n","        \"data_test\":np.array(samples[num_grid_search_samples:,:,:]),\n","    }\n","    return out"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"tDtf13qpe1vn","executionInfo":{"status":"ok","timestamp":1710431511608,"user_tz":420,"elapsed":186,"user":{"displayName":"Ni Chen","userId":"06056723126215624619"}}},"source":["#@title ATLAS Data Gen\n","\n","def get_atlas_dataset_3D(rand_key, num_grid_search_samples, test_samples):\n","  total_samples = num_grid_search_samples + test_samples\n","\n","  id = '1SLejANPHTA_eSJhIjCk9WGeFsKSEMZMx'\n","  filename = 'atlas_3d.npz'\n","  if not os.path.exists(filename):\n","    !gdown --id $id\n","  data = np.load(filename)['data']/255.0\n","\n","  scan_ids = [0, 1, 4, 7, 9, 11, 14, 16, 18, 20, 23, 24, 28]\n","  samples = resize(data[scan_ids,...], (len(scan_ids), RES, RES, RES))\n","  new_samples = random.permutation(rand_key, samples)\n","\n","  out = {\n","      \"data_grid_search\":np.array(new_samples[:num_grid_search_samples,:,:]),\n","      \"data_test\":np.array(new_samples[num_grid_search_samples:,:,:]),\n","  }\n","  return out"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"QwE32rAwuJjS","executionInfo":{"status":"error","timestamp":1710431538843,"user_tz":420,"elapsed":13473,"user":{"displayName":"Ni Chen","userId":"06056723126215624619"}},"colab":{"base_uri":"https://localhost:8080/","height":491},"outputId":"dd3e8117-7950-4dda-c334-ca8cc657bc13"},"source":["#@title Load Datasets\n","\n","visualize = True #@param {type:\"boolean\"}\n","num_grid_search_samples = 6 #@param\n","num_test_samples =  6#@param\n","\n","#@markdown Shepp Dataset\n","load_shepp = False #@param {type:\"boolean\"}\n","\n","#@markdown ATLAS Dataset\n","load_atlas = True #@param {type:\"boolean\"}\n","\n","datasets = {}\n","if load_shepp:\n","    print('Loading Shepp Dataset')\n","    datasets['shepp'] = get_shepp_dataset_3D(rand_key, num_grid_search_samples, num_test_samples)\n","    print('Shepp Dataset Loaded')\n","if load_atlas:\n","    print('Loading ATLAS Dataset')\n","    datasets['atlas'] = get_atlas_dataset_3D(rand_key, num_grid_search_samples, num_test_samples)\n","    print('ATLAS Dataset Loaded')\n","\n","x1 = np.linspace(0, 1, RES+1)[:-1] # use full image resolution\n","x_train = np.stack(np.meshgrid(x1,x1,x1), axis=-1)\n","x_test = x_train\n","\n","def plot_dataset(dataset):\n","    plt.imshow(dataset['data_test'][0,:,:,0])\n","    plt.colorbar()\n","    plt.show()\n","\n","if visualize:\n","    for dataset in datasets:\n","        print(f'Dataset {dataset}')\n","        plot_dataset(datasets[dataset])"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading ATLAS Dataset\n","/usr/local/lib/python3.10/dist-packages/gdown/cli.py:138: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  warnings.warn(\n","Downloading...\n","From (original): https://drive.google.com/uc?id=1SLejANPHTA_eSJhIjCk9WGeFsKSEMZMx\n","From (redirected): https://drive.google.com/uc?id=1SLejANPHTA_eSJhIjCk9WGeFsKSEMZMx&confirm=t&uuid=b791fad1-04b8-414e-a74b-d3f0acdd7cf0\n","To: /content/atlas_3d.npz\n","100% 268M/268M [00:01<00:00, 145MB/s]\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'resize' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-f2d5c6ff409f>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mload_atlas\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading ATLAS Dataset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'atlas'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_atlas_dataset_3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrand_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_grid_search_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_test_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ATLAS Dataset Loaded'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-4af4e0af5e3d>\u001b[0m in \u001b[0;36mget_atlas_dataset_3D\u001b[0;34m(rand_key, num_grid_search_samples, test_samples)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mscan_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m23\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscan_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscan_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0mnew_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrand_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'resize' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"gg-pce8Eu1i8"},"source":["# Network setup"]},{"cell_type":"code","metadata":{"id":"rPTApnhIu2jr"},"source":["#@title Define ReLU Network\n","\n","network_depth = 4 #@param\n","network_width = 256 #@param\n","\n","def make_network(num_layers, num_channels):\n","  layers = []\n","  for i in range(num_layers-1):\n","      layers.append(stax.Dense(num_channels))\n","      layers.append(stax.Relu)\n","  layers.append(stax.Dense(1))\n","  layers.append(stax.Sigmoid)\n","  return stax.serial(*layers)\n","\n","init_fn, apply_fn = make_network(network_depth, network_width)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7qrwDDUTShNZ"},"source":["## Setup 3D encoder\n","\n","Our input embedding is of the form: \\\n","> $\\gamma(\\mathbf v) = (a_0 \\sin(\\pi b_0^\\top \\mathbf v), a_0 \\cos(\\pi b_0^\\top \\mathbf v),a_1 \\sin(\\pi b_1^\\top \\mathbf v), a_1 \\cos(\\pi b_1^\\top \\mathbf v),...)$\n","\n","This creates a kernel of the form: \\\n","> $k_\\gamma(\\mathbf v_1, \\mathbf v_2) = \\sum_{i=1}^m a_i^2 \\cos(\\pi b_i^\\top (\\mathbf v_1 - \\mathbf v_2))$"]},{"cell_type":"code","metadata":{"id":"otZXvBuLu4gx"},"source":["#@title Generate Fixed Embeddings\n","\n","embedding_size = 256 #@param\n","\n","include_basic = False #@param {type:\"boolean\"}\n","include_posenc = False #@param {type:\"boolean\"}\n","#@markdown same as posenc, but with more samples\n","include_new_posenc = True #@param {type:\"boolean\"}\n","visualize = []\n","\n","enc_dict = {}\n","\n","input_encoder = lambda x, a, b: np.concatenate([a * np.sin((2.*np.pi*x) @ b.T),\n","                                                a * np.cos((2.*np.pi*x) @ b.T)], axis=-1) #/ np.linalg.norm(a) * np.sqrt(a.shape[0])\n","\n","def compute_new_posenc(mres):\n","  bvals = 2.**np.linspace(0,mres,embedding_size//3) - 1.\n","  bvals = np.stack([bvals, np.zeros_like(bvals), np.zeros_like(bvals)], -1)\n","  bvals = np.concatenate([bvals, np.roll(bvals, 1, axis=-1), np.roll(bvals, 2, axis=-1)], 0)\n","  avals = np.ones((bvals.shape[0]))\n","  return avals, bvals\n","\n","def compute_basic():\n","  bvals = np.eye(3)\n","  avals = np.ones((bvals.shape[0]))\n","  return avals, bvals\n","\n","def visualize_encoders(enc_dict, keys=None):\n","    if keys is None:\n","        keys = enc_dict.keys()\n","\n","    P = len(keys)\n","    plt.figure(figsize=(15,5))\n","    slices = {}\n","    for i, enc in enumerate(keys):\n","        plt.subplot(1,P,i+1)\n","        avals, bvals = enc_dict[enc]\n","        plt.scatter(bvals[:,0], bvals[:,1], marker='o', s=10, label=enc)\n","        plt.title(f'{enc} b values')\n","        plt.axis('equal')\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dn2PccWxUfED"},"source":["# MRI Mask"]},{"cell_type":"code","metadata":{"id":"0wGzyrG3USlO"},"source":["def mri_mask(shape, nsamp):\n","  mean = np.array(shape)//2\n","  cov = np.eye(len(shape)) * (2*shape[0])\n","  samps = random.multivariate_normal(rand_key, mean, cov, shape=(1,nsamp))[0,...].astype(np.int32)\n","  mask = np.zeros(shape)\n","  inds = []\n","  for i in range(samps.shape[-1]):\n","    inds.append(samps[...,i])\n","  mask = index_update(mask, index[inds], 1.)\n","  return mask"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q9c29kpX_iQk"},"source":["# Train Model"]},{"cell_type":"code","metadata":{"id":"kzW5ZOyPN7Sg"},"source":["@jit\n","def run_model(params, x, avals, bvals):\n","    if avals is not None:\n","        x = input_encoder(x, avals, bvals)\n","    return np.reshape(apply_fn(params, np.reshape(x, (-1, x.shape[-1]))), (x.shape[0], x.shape[1], x.shape[2]))\n","\n","compute_mri = jit(lambda params, x, a, b, y, mask: np.fft.fft(np.fft.fft(np.fft.fft(run_model(params, x, a, b), axis=0), axis=1), axis=2)*mask.astype(np.complex64))\n","model_loss_mri = jit(lambda params, x, a, b, y, mask: .5 * np.mean(np.abs((compute_mri(params, x, a, b, y, mask) - y) ** 2)))\n","model_loss = jit(lambda params, x, a, b, y, mask, image: .5 * np.abs(np.mean((np.clip(run_model(params, x, a, b), 0.0, 1.0) - image) ** 2)))\n","model_psnr = jit(lambda params, x, a, b, y, mask, image: -10 * np.log10(2.*model_loss(params, x, a, b, y, mask, image)))\n","model_grad_loss = jit(lambda params, x, a, b, y, mask, image: jax.grad(model_loss_mri)(params, x, a, b, y, mask))\n","\n","\n","GROUPS_MODEL = {'Test PSNR':[], 'Train PSNR':[]}\n","def train_model(lr, iters, train_data, name='', plot_groups=None):\n","    opt_init, opt_update, get_params = optimizers.adam(lr)\n","    opt_update = jit(opt_update)\n","\n","    if train_data[2] is not None:\n","      init_shape = train_data[2].shape[0]*2\n","    else:\n","      init_shape = 3\n","    _, params = init_fn(rand_key, (-1, init_shape))\n","    opt_state = opt_init(params)\n","\n","    train_psnrs = []\n","    test_psnrs = []\n","    xs = []\n","    if plot_groups is not None:\n","        plot_groups['Test PSNR'].append(f'{name}_test')\n","        plot_groups['Train PSNR'].append(f'{name}_train')\n","    for i in tqdm(range(iters), desc='train iter', leave=False):\n","        opt_state = opt_update(i, model_grad_loss(get_params(opt_state), *train_data), opt_state)\n","        if i % 25 == 0:\n","            train_psnr = model_psnr(get_params(opt_state), *train_data)\n","            test_psnr = train_psnr #model_psnr(get_params(opt_state), *test_data)\n","            train_psnrs.append(train_psnr)\n","            # test_psnrs.append(test_psnr)\n","            test_psnrs.append(test_psnr)\n","            xs.append(i)\n","            if plot_groups is not None:\n","                plotlosses_model.update({f'{name}_train':train_psnr, f'{name}_test':test_psnr}, current_step=i)\n","        if i % 100 == 0 and i != 0 and plot_groups is not None:\n","            plotlosses_model.send()\n","    if plot_groups is not None:\n","        plotlosses_model.send()\n","    results = {\n","        'state': get_params(opt_state),\n","        'train_psnrs': train_psnrs,\n","        'test_psnrs': test_psnrs,\n","        'xs': xs,\n","        'final_test' : run_model(get_params(opt_state), train_data[0], train_data[1], train_data[2])\n","    }\n","    return results\n","\n","\n","def train_gridopt(lr, iters, train_data, name='', plot_groups=None):\n","\n","    compute_mri = jit(lambda params, y, mask: np.fft.fft(np.fft.fft(np.fft.fft(params, axis=0), axis=1), axis=2)*mask.astype(np.complex64))\n","    model_loss_mri = jit(lambda params, y, mask: .5 * np.mean(np.abs((compute_mri(jax.nn.sigmoid(params), y, mask) - y) ** 2)))\n","    model_loss = jit(lambda params, y, mask, image: .5 * np.abs(np.mean((np.clip(jax.nn.sigmoid(params), 0.0, 1.0) - image) ** 2)))\n","    model_psnr = jit(lambda params, y, mask, image: -10 * np.log10(2.*model_loss(params, y, mask, image)))\n","    model_grad_loss = jit(lambda params, y, mask, image: jax.grad(model_loss_mri)(params, y, mask))\n","\n","    opt_init, opt_update, get_params = optimizers.adam(lr)\n","    opt_update = jit(opt_update)\n","\n","    grid = np.zeros((RES, RES, RES))\n","    opt_state = opt_init(grid)\n","\n","    train_psnrs = []\n","    test_psnrs = []\n","    xs = []\n","    if plot_groups is not None:\n","        plot_groups['Test PSNR'].append(f'{name}_test')\n","        plot_groups['Train PSNR'].append(f'{name}_train')\n","    for i in tqdm(range(iters), desc='train iter', leave=False):\n","        opt_state = opt_update(i, model_grad_loss(get_params(opt_state), *train_data), opt_state)\n","        if i % 25 == 0:\n","            train_psnr = model_psnr(get_params(opt_state), *train_data)\n","            test_psnr = train_psnr\n","            train_psnrs.append(train_psnr)\n","            test_psnrs.append(test_psnr)\n","            xs.append(i)\n","            if plot_groups is not None:\n","                plotlosses_model.update({f'{name}_train':train_psnr, f'{name}_test':test_psnr}, current_step=i)\n","        if i % 100 == 0 and i != 0 and plot_groups is not None:\n","            plotlosses_model.send()\n","    if plot_groups is not None:\n","        plotlosses_model.send()\n","    results = {\n","        'state': get_params(opt_state),\n","        'train_psnrs': train_psnrs,\n","        'test_psnrs': test_psnrs,\n","        'xs': xs,\n","        'final_test' : jax.nn.sigmoid(get_params(opt_state))\n","    }\n","    return results"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y_VWnH_haZZj"},"source":["#@title MRI parameters\n","\n","nsamp = 200000#@param\n","mask = np.fft.fftshift(mri_mask((RES,RES,RES), nsamp)).astype(np.complex64)\n","print('sparsity:', np.sum(np.abs(mask))/np.prod(mask.shape))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"daJoQDbNOFJc"},"source":["#@title Grid Search bval distributions\n","#@markdown The models are trained on a different set of data. The top distribution is added to the list.\n","\n","lr =  2e-3#@param\n","training_steps =  1000#@param\n","target_distribution = \"atlas\" #@param [\"shepp\", \"atlas\"]\n","num_images =  6#@param\n","min_scale =  2#0.5#@param\n","max_scale =  6#3.5#@param\n","num_scales =  5#7#@param\n","\n","bvals = random.normal(rand_key, (embedding_size, 3))\n","avals = np.ones((bvals.shape[0]))\n","scales = np.linspace(min_scale, max_scale, num_scales)\n","print(f'searching over, {scales}')\n","\n","if num_images == 1:\n","    plt_groups = {'Test PSNR':[], 'Train PSNR':[]}\n","    plotlosses_model = PlotLosses(groups=plt_groups)\n","else:\n","    plt_groups = None\n","result_psnrs = []\n","for scale in tqdm(scales, desc='Scale', leave=False):\n","    scale_results = []\n","    for i in tqdm(range(num_images), desc='Image', leave=False):\n","        image = datasets[target_distribution]['data_grid_search'][i,:,:,:]\n","        # y for MRI is just FFT (masking is in compute_mri)\n","        y_train = np.fft.fft(np.fft.fft(np.fft.fft(image, axis=0), axis=1), axis=2)\n","        train_data = (x_train, avals, bvals*scale, y_train, mask, image)\n","        scale_results.append(train_model(lr, training_steps, train_data,\n","                                         name=scale, plot_groups=plt_groups)['test_psnrs'][-1])\n","    result_psnrs.append(scale_results)\n","\n","result_psnrs = np.array(result_psnrs)\n","plt.errorbar(scales, np.mean(result_psnrs, axis=-1), yerr=np.std(result_psnrs, axis=-1))\n","plt.title('Grid search')\n","plt.xlabel('gaussian scale')\n","plt.ylabel('PSNR')\n","plt.show()\n","\n","best_scale = scales[np.argmax(np.mean(result_psnrs, axis=-1))]\n","print(f'Adding gaussian scale {best_scale} to encoding methods')\n","enc_dict[f'gaussian_{\"%.2f\" % best_scale}'] = (avals, bvals*best_scale)\n","\n","del result_psnrs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OWZaUSB1EMQS"},"source":["#@title Grid Search posenc distributions\n","#@markdown The models are trained on a different set of data. The top distribution is added to the list.\n","\n","lr =  2e-3#@param\n","training_steps =  1000#@param\n","target_distribution = \"atlas\" #@param [\"shepp\", \"atlas\"]\n","num_images =  6#@param\n","min_scale =  1#@param\n","max_scale =  5#@param\n","scales = np.arange(min_scale, max_scale+1)\n","\n","if num_images == 1:\n","    plt_groups = {'Test PSNR':[], 'Train PSNR':[]}\n","    plotlosses_model = PlotLosses(groups=plt_groups)\n","else:\n","    plt_groups = None\n","result_psnrs = []\n","for scale in tqdm(scales, desc='Scale', leave=False):\n","    avals, bvals = compute_new_posenc(scale)\n","    scale_results = []\n","    for i in tqdm(range(num_images), desc='Image', leave=False):\n","        image = datasets[target_distribution]['data_grid_search'][i,:,:,:]\n","        # y for MRI is just FFT (masking is in compute_mri)\n","        y_train = np.fft.fft(np.fft.fft(np.fft.fft(image, axis=0), axis=1), axis=2)\n","        train_data = (x_train, avals, bvals, y_train, mask, image)\n","        scale_results.append(train_model(lr, training_steps, train_data,\n","                                         name=scale, plot_groups=plt_groups)['test_psnrs'][-1])\n","    result_psnrs.append(scale_results)\n","\n","result_psnrs = np.array(result_psnrs)\n","plt.errorbar(scales, np.mean(result_psnrs, axis=-1), yerr=np.std(result_psnrs, axis=-1))\n","plt.title('Grid search')\n","plt.xlabel('posenc scale')\n","plt.ylabel('PSNR')\n","plt.show()\n","\n","best_scale = scales[np.argmax(np.mean(result_psnrs, axis=-1))]\n","print(f'Adding posenc scale {best_scale} to encoding methods')\n","enc_dict[f'posenc_{\"%.2f\" % best_scale}'] = compute_new_posenc(best_scale)\n","\n","del result_psnrs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jUTZhXK_Sb-t"},"source":["#@title Define Final Experiment Parameters\n","\n","params = {\n","    'shepp': {\n","        'lr': 2e-3,\n","        'no_enc_lr': 2e-3,\n","        'basic_lr': 2e-3,\n","        'gridopt_lr': 2e-3,\n","        'posenc_scale': 4,\n","        'gaussian_scale': 2,\n","    },\n","    'atlas': {\n","        'lr': 2e-3,\n","        'no_enc_lr': 2e-3,\n","        'basic_lr': 2e-3,\n","        'gridopt_lr': 2e-3,\n","        'posenc_scale': 4,\n","        'gaussian_scale': 5,\n","    }\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YW-7sEF2vOrG"},"source":["#@title Train Models\n","\n","training_steps =  1000#@param\n","\n","target_distribution = \"atlas\" #@param [\"shepp\", \"atlas\"]\n","\n","num_images =  6#@param\n","\n","if num_images == 1:\n","    plt_groups = {'Test PSNR':[], 'Train PSNR':[]}\n","    plotlosses_model = PlotLosses(groups=plt_groups)\n","else:\n","    plt_groups = None\n","\n","outputs = {}\n","\n","# no encoding\n","lr = params[target_distribution]['no_enc_lr']\n","outputs['no_encoding'] = []\n","for i in tqdm(range(num_images), desc='no encoding', leave=False):\n","  image = datasets[target_distribution]['data_test'][i,:,:,:]\n","  y_train = np.fft.fft(np.fft.fft(np.fft.fft(image, axis=0), axis=1), axis=2)\n","  outputs['no_encoding'].append(train_model(lr, training_steps,\n","                                            (x_train, None, None, y_train, mask, image),\n","                                            name='no_encoding', plot_groups=plt_groups))\n","\n","\n","# basic encoding\n","avals, bvals = compute_basic()\n","lr = params[target_distribution]['basic_lr']\n","outputs['basic'] = []\n","for i in tqdm(range(num_images), desc='basic', leave=False):\n","  image = datasets[target_distribution]['data_test'][i,:,:,:]\n","  y_train = np.fft.fft(np.fft.fft(np.fft.fft(image, axis=0), axis=1), axis=2)\n","  train_data = (x_train, avals, bvals, y_train, mask, image)\n","  outputs['basic'].append(train_model(lr, training_steps, train_data, name='basic', plot_groups=plt_groups))\n","\n","\n","# new posenc\n","avals, bvals = compute_new_posenc(params[target_distribution]['posenc_scale'])\n","lr = params[target_distribution]['lr']\n","outputs['new_posenc'] = []\n","for i in tqdm(range(num_images), desc='new posenc', leave=False):\n","  image = datasets[target_distribution]['data_test'][i,:,:,:]\n","  y_train = np.fft.fft(np.fft.fft(np.fft.fft(image, axis=0), axis=1), axis=2)\n","  train_data = (x_train, avals, bvals, y_train, mask, image)\n","  outputs['new_posenc'].append(train_model(lr, training_steps, train_data, name='new_posenc', plot_groups=plt_groups))\n","\n","\n","# gaussian\n","bvals = random.normal(rand_key, (embedding_size, 3)) * params[target_distribution]['gaussian_scale']\n","avals = np.ones((bvals.shape[0]))\n","lr = params[target_distribution]['lr']\n","outputs['gaussian'] = []\n","for i in tqdm(range(num_images), desc='gaussian', leave=False):\n","  image = datasets[target_distribution]['data_test'][i,:,:,:]\n","  y_train = np.fft.fft(np.fft.fft(np.fft.fft(image, axis=0), axis=1), axis=2)\n","  train_data = (x_train, avals, bvals, y_train, mask, image)\n","  outputs['gaussian'].append(train_model(lr, training_steps, train_data, name='gaussian', plot_groups=plt_groups))\n","\n","\n","# grid optimization baseline\n","outputs['gridopt'] = []\n","lr = params[target_distribution]['gridopt_lr']\n","for i in tqdm(range(num_images), desc='gridopt', leave=False):\n","  image = datasets[target_distribution]['data_test'][i,:,:,:]\n","  y_train = np.fft.fft(np.fft.fft(np.fft.fft(image, axis=0), axis=1), axis=2)\n","  train_data = (y_train, mask, image)\n","  test_data = train_data\n","  outputs['gridopt'].append(train_gridopt(lr, training_steps, train_data, name='gridopt', plot_groups=plt_groups))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9WaL9uTBkVlC"},"source":["# grid optimization baseline\n","outputs['gridopt'] = []\n","lr = 1e-1#params[target_distribution]['gridopt_lr']\n","for i in tqdm(range(num_images), desc='gridopt', leave=False):\n","  image = datasets[target_distribution]['data_test'][i,:,:,:]\n","  y_train = np.fft.fft(np.fft.fft(np.fft.fft(image, axis=0), axis=1), axis=2)\n","  train_data = (y_train, mask, image)\n","  test_data = train_data\n","  outputs['gridopt'].append(train_gridopt(lr, training_steps, train_data, name='gridopt', plot_groups=plt_groups))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ubKm-fOSvVSU"},"source":["#@title Plot Results\n","\n","bar_graph = True #@param {type:\"boolean\"}\n","image_reconstructions = True #@param {type:\"boolean\"}\n","test_img_id =  1#@param\n","\n","names = list(outputs.keys())\n","\n","image_test = datasets[target_distribution]['data_test'][test_img_id,:,:,:]\n","\n","xvals = np.arange(len(names))\n","test_values = np.array([[outputs[n][i]['test_psnrs'][-1] for i in range(len(outputs[n]))] for n in names])\n","test_values_mean = np.mean(test_values, axis=-1)\n","test_values_std = np.std(test_values, axis=-1)\n","train_values = np.array([[outputs[n][i]['train_psnrs'][-1] for i in range(len(outputs[n]))] for n in names])\n","train_values_mean = np.mean(train_values, axis=-1)\n","train_values_std = np.std(train_values, axis=-1)\n","inds = np.argsort(test_values_mean)\n","names_sort = [names[i] for i in inds]\n","\n","if bar_graph:\n","    plt.figure(figsize=(20,5))\n","    plt.subplot(1,2,1)\n","    plt.bar(xvals+2, test_values_mean[inds], color=colors[0], alpha=.5, yerr=test_values_std)\n","    plt.xticks([])\n","    plt.ylim(test_values_mean.min()-test_values_std.max()-1, test_values_mean.max()+test_values_std.max()+1)\n","    plt.title(f'Fitting {target_distribution} Test')\n","    prnt_vals = ['%.2f' % x for x in test_values_mean[inds].tolist()]\n","    plt.table(cellText=[prnt_vals],\n","              rowLabels=['PSNR'],\n","              colLabels=names_sort,\n","              loc='bottom',\n","              bbox=[0, -.2, 1, 0.2])\n","\n","    plt.subplot(1,2,2)\n","    plt.bar(xvals, train_values_mean[inds], color=colors[0], alpha=.5, yerr=train_values_std)\n","    # plt.xticks(xvals, names_sort, rotation=60)\n","    plt.xticks([])\n","    plt.ylim(train_values_mean.min()-train_values_std.max()-1, train_values_mean.max()+train_values_std.max()+1)\n","    plt.title(f'Fitting {target_distribution} Train')\n","    plt.table(cellText=[['%.2f' % x for x in train_values_mean[inds].tolist()]],\n","        rowLabels=['PSNR'],\n","        colLabels=names_sort,\n","        loc='bottom',\n","        bbox=[0, -.2, 1, 0.2])\n","\n","    plt.show()\n","\n","if image_reconstructions:\n","    print('----------------------------------------')\n","    print('                  Test')\n","    print('----------------------------------------')\n","    plt.figure(figsize=(28,6))\n","    for i, p in enumerate(names_sort):\n","        pred = outputs[p][test_img_id]['final_test']\n","        plt.subplot(1,len(names)+1,i+1)\n","        plt.imshow(pred[:,:,20])\n","        plt.title(p)\n","\n","    plt.subplot(1,len(names)+1,len(names)+1)\n","    plt.imshow(image_test[:,:,20])\n","    plt.title('truth test')\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GahVf1s4-Dw5"},"source":["np.savez('3D_MRI_atlas.npz', outputs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tbZ8v4cS_K3o"},"source":["test_img_id = 1\n","image_test = datasets[target_distribution]['data_test'][test_img_id,:,:,:]\n","plt.figure(figsize=(28,6))\n","for i, p in enumerate(names_sort):\n","    pred = outputs[p][test_img_id]['final_test']\n","    plt.subplot(1,len(names)+1,i+1)\n","    plt.imshow(pred[:,:,35])\n","    plt.title(p)\n","\n","plt.subplot(1,len(names)+1,len(names)+1)\n","plt.imshow(image_test[:,:,35])\n","plt.title('truth test')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tDWn0IwanjBx"},"source":["ind = 1\n","slice = 35\n","pred_ne = outputs['no_encoding'][ind]['final_test'][:,:,slice]\n","pred_g = outputs['gaussian'][ind]['final_test'][:,:,slice]\n","plt.imsave('3D_MRI_no_encoding.png', pred_ne, cmap='gray')\n","plt.imsave('3D_MRI_gaussian_encoding.png', pred_g, cmap='gray')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"im4g9ga4otvu"},"source":[],"execution_count":null,"outputs":[]}]}